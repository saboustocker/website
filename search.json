[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Slides",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nSubtitle\n\n\n\n\n\n\n\n\nAug 15, 2025\n\n\nJob Talk @ IBT-HSG\n\n\n¬†\n\n\n\n\n\n\nAug 13, 2025\n\n\nAutomating online data collection using web-scraping\n\n\nTech Lunch @ CBDR\n\n\n\n\n\n\nMay 5, 2025\n\n\nA Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty\n\n\nFoKo 4\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/techlunch31032025.html#our-program",
    "href": "slides/techlunch31032025.html#our-program",
    "title": "Automating online data collection using web-scraping",
    "section": "Our program",
    "text": "Our program\n\nWhy would I want to automate web-scraping?\nThe right tool for the job‚Ä¶\n‚Ä¶ but how do I know the job?\nSome practical examples and code\nQ&A\n(Optional: some funny statistics)"
  },
  {
    "objectID": "slides/techlunch31032025.html#what-i-used-it-for",
    "href": "slides/techlunch31032025.html#what-i-used-it-for",
    "title": "Automating online data collection using web-scraping",
    "section": "What I used it for",
    "text": "What I used it for\n\nexporting stock developments\ndetermining median hotel prices\nextracting word frequency\ncircumventing copyright protection (flipbook) ü§´\nmaking a üí©ton of data entries"
  },
  {
    "objectID": "slides/techlunch31032025.html#in-general",
    "href": "slides/techlunch31032025.html#in-general",
    "title": "Automating online data collection using web-scraping",
    "section": "In general",
    "text": "In general\n\nStructured data from webpages without export button\nAnalyzing online-data (forums, product reviews, ‚Ä¶)\nSystematic interactions with specific sites\nFun personal projects üòä\nüí≠‚Ä¶\n\nBut!! Be mindful of the ethical, regulatory and legal impact of your project."
  },
  {
    "objectID": "slides/techlunch31032025.html#the-right-tool-for-the-job",
    "href": "slides/techlunch31032025.html#the-right-tool-for-the-job",
    "title": "Automating online data collection using web-scraping",
    "section": "The right tool for the job‚Ä¶",
    "text": "The right tool for the job‚Ä¶"
  },
  {
    "objectID": "slides/techlunch31032025.html#selenium",
    "href": "slides/techlunch31032025.html#selenium",
    "title": "Automating online data collection using web-scraping",
    "section": "Selenium",
    "text": "Selenium\n\nautomated interaction with a web-browser\n\n\n\nPro\n\ninteraction with web-browser\ninput data (e.g.¬†forms, text)\ninteraction with dynamic sites (JavaScript)\n\n\nCon\n\nslow\nlearning curve\npain in the butt sometimes"
  },
  {
    "objectID": "slides/techlunch31032025.html#beautifulsoup4",
    "href": "slides/techlunch31032025.html#beautifulsoup4",
    "title": "Automating online data collection using web-scraping",
    "section": "BeautifulSoup4",
    "text": "BeautifulSoup4\n\nextracts HTML structures and contents from webpages\n\n\n\nPro\n\nextracting html components of a single URL / a list of URLs where structure is standardized\neasy translations of objects into dataframes\n\n\nCon\n\ninteraction with web-browser\ninput data (e.g.¬†forms, text)\ninteraction with dynamic sites (JavaScript)"
  },
  {
    "objectID": "slides/techlunch31032025.html#beautifulsoup",
    "href": "slides/techlunch31032025.html#beautifulsoup",
    "title": "Automating online data collection using web-scraping",
    "section": "Beautifulsoup",
    "text": "Beautifulsoup\nHow many chairs (and ‚Äúsub-chairs‚Äù) do we have at the psychological Institute in Zurich?\n\n5 chairs and 35 ‚Äúsub-chairs‚Äù\n5 chairs and 20 ‚Äúsub-chairs‚Äù\n5 chairs and 29 ‚Äúsub-chairs‚Äù"
  },
  {
    "objectID": "slides/techlunch31032025.html#beautifulsoup-1",
    "href": "slides/techlunch31032025.html#beautifulsoup-1",
    "title": "Automating online data collection using web-scraping",
    "section": "Beautifulsoup",
    "text": "Beautifulsoup\nHow many chairs (and ‚Äúsub-chairs‚Äù) do we have at the psychological Institute in Zurich?\n\n5 chairs and 35 ‚Äúsub-chairs‚Äù\n5 chairs and 20 ‚Äúsub-chairs‚Äù\n5 chairs and 29 ‚Äúsub-chairs‚Äù"
  },
  {
    "objectID": "slides/techlunch31032025.html#beautifulsoup-2",
    "href": "slides/techlunch31032025.html#beautifulsoup-2",
    "title": "Automating online data collection using web-scraping",
    "section": "Beautifulsoup",
    "text": "Beautifulsoup\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n\nbase_url = \"https://www.psychologie.uzh.ch\"\noverview_url = base_url + \"/de/bereiche/uebersicht.html\"\n\nresponse = requests.get(overview_url)\nsoup = BeautifulSoup(response.text,\"html.parser\")\n\n\n\n## Level 1 subpages\nsubpage_links = []\nall_data = []\n\n\nfor link in soup.find_all(\"a\",href=True):\n    href = link[\"href\"]\n    if href.startswith(\"/de/bereiche/\") and href.endswith(\".html\"):\n        subpage_links.append(base_url+href)\n        print(base_url+href)\n\nfor subpage_url in subpage_links:\n    \n    print(f\"\\nScraping {subpage_url}\")\n    response = requests.get(subpage_url)\n    sub_soup = BeautifulSoup(response.text,\"html.parser\")\n\n    chair = sub_soup.find(\"h1\") ## e.g. Entwicklungspsychologie\n    chair_name = chair.get_text(strip=True)\n    print(chair_name)\n\n    tables = sub_soup.find_all(\"table\", class_=\"basic\") ## e.g. \"Entwicklungspsychologie: Kinder- und S√§uglingsalter\"\n\n    for i, table in enumerate(tables):\n        print(f\"\\nTable {i+1} in {subpage_url}\")\n        table_data = []\n        table_data.append(chair_name)\n        rows = table.find_all(\"tr\")\n\n        for i, row in enumerate(rows):\n        \n            cells = row.find_all([\"th\",\"td\"])\n            length = len(cells)\n            print(f\"\\nlen: {length}\")\n\n            if length == 2:\n                title = cells[0].get_text(strip=True) if len(cells) &gt; 0 else \"\"\n                table_data.append(title)\n                link = cells[1].find(\"a\",href=True)\n                table_data.append(link)\n                print(f\"\\niteration: {i}\")\n                print(\"Length = 2\")\n                print(f\"\\nTitle: {title}\")\n                print(f\"\\nLink: {link}\")\n                if link:\n                    full_description = []\n                    subsubpage_link = base_url + link[\"href\"]\n                    subresponse = requests.get(subsubpage_link)\n                    subsub_soup = BeautifulSoup(subresponse.text, \"html.parser\")\n                    description = subsub_soup.find(\"section\", class_=\"ContentArea\")\n                    \n                    if description:\n                        section_text = description.get_text(strip=True, separator=\" \")\n                        full_description.append(section_text)\n                        \n                    else:\n                        print(\"No section found\")\n                    description_text = \" \".join(full_description)\n                    table_data.append(description_text)\n                    print(f\"\\ndescription: {description_text}\")\n            elif length == 1 and i == 1:\n                print(f\"\\niteration: {i}\")\n                print(\"Length = 1\")\n                name = cells[0].get_text(strip=True) if len(cells) &gt; 0 else \"\"\n                print(f\"\\nName: {name}\")\n                table_data.append(name)\n            elif length == 1 and i == 2:\n                print(f\"\\niteration: {i}\")\n                print(\"Length = 1\")\n                position = cells[0].get_text(strip=True) if len(cells) &gt; 0 else \"\"\n                print(f\"\\nPosition: {position}\")\n                table_data.append(position)\n            \n            print(table_data)\n            all_data.append(table_data)\n\ndf = pd.DataFrame(all_data)\ndf.to_csv(\"beautifulsoup.csv\",index=False,sep=\";\",quoting=1,encoding=\"utf-8-sig\")"
  },
  {
    "objectID": "slides/techlunch31032025.html#selenium-1",
    "href": "slides/techlunch31032025.html#selenium-1",
    "title": "Automating online data collection using web-scraping",
    "section": "Selenium",
    "text": "Selenium\nWhat is the most-watched video on the youtube channel of UZH?\n\nDer flexible Schweif des Prions vergiftet die Hirnzellen (en: the flexible tail of the prion poisons brain cells)\nSchwebebahn mit Hochtemperatur-Supraleitung (en: Suspension railroad with high-temperature superconductivity)\nMoosforschung (en: moss research)"
  },
  {
    "objectID": "slides/techlunch31032025.html#selenium-2",
    "href": "slides/techlunch31032025.html#selenium-2",
    "title": "Automating online data collection using web-scraping",
    "section": "Selenium",
    "text": "Selenium\nWhat is the most-watched video on the youtube channel of UZH?\n\nDer flexible Schweif des Prions vergiftet die Hirnzellen (en: the flexible tail of the prion poisons brain cells)\nSchwebebahn mit Hochtemperatur-Supraleitung (en: Suspension railroad with high-temperature superconductivity)\nMoosforschung (en: moss research)"
  },
  {
    "objectID": "slides/techlunch31032025.html#selenium-3",
    "href": "slides/techlunch31032025.html#selenium-3",
    "title": "Automating online data collection using web-scraping",
    "section": "Selenium",
    "text": "Selenium\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.firefox.service import Service\nfrom webdriver_manager.firefox import GeckoDriverManager\nfrom selenium.webdriver.firefox.options import Options\nimport time\nimport re\nimport pandas as pd\n\ndata = [] \ndef text_before(text,delimiter):\n    return text.split(delimiter)[0] if delimiter in text else text\ndef text_after(text, delimiter):\n    return text.split(delimiter, 1)[1] if delimiter in text else \"\"\n\nfirefox_options = Options()\n#firefox_options.add_argument(\"--headless\")  # if you don't want to open a window\nfirefox_options.add_argument(\"--disable-gpu\")\n\ndriver = webdriver.Firefox(service=Service(GeckoDriverManager().install()), options=firefox_options)\n\nchannel_url = 'https://www.youtube.com/@uzhch/videos'\ndriver.get(channel_url)\ntime.sleep(5)\n\n## accept all cookies\ntry:\n    accept_button = driver.find_element(By.XPATH, \"/html/body/c-wiz/div/div/div/div[2]/div[1]/div[3]/div[1]/form[2]/div/div/button/span\")\n    accept_button.click()\n    print(\"Cookies accepted.\")\nexcept Exception as e:\n    print(f\"Could not accept cookies: {e}\")\n\ntime.sleep(5)\n\nstart_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\nprint(start_height)\nmax_attempts = 100\nattempt = 0\n\nwhile attempt &lt; max_attempts:    \n    html = driver.find_element(By.TAG_NAME, 'html')\n    html.send_keys(Keys.END)\n    time.sleep(3)\n    new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n    print(new_height)\n    if new_height == start_height:\n        break\n    else: \n        start_height = new_height\n\n    attempt+=1\n\nlinks = driver.find_elements(By.CSS_SELECTOR, \"a#video-title-link\")\naria_labels = [link.get_attribute(\"aria-label\") for link in links]\nfor label in aria_labels:\n    print(label)\n\n    title = text_before(label,\"by Universit√§t Z√ºrich\")\n    print(title)\n    \n    views = text_after(label,\"by Universit√§t Z√ºrich\")\n    views = text_before(views,\" views \")\n    print(views)\n    \n    date = text_after(label, views+\" views \")\n    date = text_before(date,\" ago \")\n    print(date)\n    \n    duration = text_after(label,date+\" ago \")\n    print(duration)\n\n    data.append([title, views, date, duration])\n\ndf = pd.DataFrame(data, columns=[\"Title\", \"Views\", \"Date\", \"Duration\"])\ndf.to_csv(\"youtube_data.csv\",index=False,quoting=1,sep=\";\",encoding=\"utf-8\")"
  },
  {
    "objectID": "slides/techlunch31032025.html#qa",
    "href": "slides/techlunch31032025.html#qa",
    "title": "Automating online data collection using web-scraping",
    "section": "Q&A",
    "text": "Q&A"
  },
  {
    "objectID": "slides/techlunch31032025.html#amount-of-videos-uploaded-per-year-on-uzhs-youtube-channel",
    "href": "slides/techlunch31032025.html#amount-of-videos-uploaded-per-year-on-uzhs-youtube-channel",
    "title": "Automating online data collection using web-scraping",
    "section": "Amount of videos uploaded per year on UZH‚Äôs youtube channel",
    "text": "Amount of videos uploaded per year on UZH‚Äôs youtube channel"
  },
  {
    "objectID": "slides/techlunch31032025.html#duration-of-videos-across-time",
    "href": "slides/techlunch31032025.html#duration-of-videos-across-time",
    "title": "Automating online data collection using web-scraping",
    "section": "Duration of Videos across time",
    "text": "Duration of Videos across time"
  },
  {
    "objectID": "slides/techlunch31032025.html#most-frequently-used-words-in-descriptions-of-our-sub-chairs",
    "href": "slides/techlunch31032025.html#most-frequently-used-words-in-descriptions-of-our-sub-chairs",
    "title": "Automating online data collection using web-scraping",
    "section": "Most frequently used words in descriptions of our (sub-)chairs",
    "text": "Most frequently used words in descriptions of our (sub-)chairs"
  },
  {
    "objectID": "slides/techlunch31032025.html#oh-hello-there",
    "href": "slides/techlunch31032025.html#oh-hello-there",
    "title": "Automating online data collection using web-scraping",
    "section": "‚Ä¶ oh hello there!",
    "text": "‚Ä¶ oh hello there!"
  },
  {
    "objectID": "slides/techlunch31032025.html#length-of-descriptions-in-words",
    "href": "slides/techlunch31032025.html#length-of-descriptions-in-words",
    "title": "Automating online data collection using web-scraping",
    "section": "Length of descriptions in words",
    "text": "Length of descriptions in words"
  },
  {
    "objectID": "slides/foko4_20250505.html#aim",
    "href": "slides/foko4_20250505.html#aim",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Aim",
    "text": "Aim\n\nCan we diagnose state-dependent mechanisms influencing decisions under risk and uncertainty by utilizing verbal protocols as data?\n\n\n\nlast time, I did ask you that I want to find out if we can use think-aloud protocols for diagnosing state-dependent mechanisms, this time I am telling you if I managed to do exactly that!\ntoday‚Äôs agenda:\n\naim and research questions\nmethodology\nresults\ncontext\nlimitations\nquestions"
  },
  {
    "objectID": "slides/foko4_20250505.html#research-questions",
    "href": "slides/foko4_20250505.html#research-questions",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Research Questions",
    "text": "Research Questions\n\n\nTo what degree can natural language data from think-aloud protocols be used to reliably classify different classes of experimentally induced psychological mechanisms?\nTo what extent are the language markers associated with each psychological mechanism unique to their respective class (vs.¬†co-occurring across multiple classes)?\nIf there are language markers that overlap across classes of mechanisms, to what extent can classes of decision mechanisms still be distinguished from each other?"
  },
  {
    "objectID": "slides/foko4_20250505.html#research-questions-1",
    "href": "slides/foko4_20250505.html#research-questions-1",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Research Questions",
    "text": "Research Questions\n\n\nTo what degree can natural language data from think-aloud protocols be used to reliably classify different classes of experimentally induced psychological mechanisms?\nTo what extent are the language markers associated with each psychological mechanism unique to their respective class (vs.¬†co-occurring across multiple classes)?\nIf there are language markers that overlap across classes of mechanisms, to what extent can classes of decision mechanisms still be distinguished from each other?"
  },
  {
    "objectID": "slides/foko4_20250505.html#specification-curve-analysis",
    "href": "slides/foko4_20250505.html#specification-curve-analysis",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Specification Curve Analysis",
    "text": "Specification Curve Analysis\n\nSimonsohn, Simmons, and Nelson (2020)\n\n\n\n\n\n\nMeasurement metric (AUC-ROC / h-score)\nDominance of two data preselection strategies without clear pattern between the two emerging\nDominance of two classifiers with indication that one is better than the other\nNo visible pattern\n\n\n\n\n\n\n\n\n\nFigure¬†1: Graph depicting symbolic specification curve analysis. (grey dotted line indicates how ‚Äúdots‚Äù in categories indicate the specific configuration.)"
  },
  {
    "objectID": "slides/foko4_20250505.html#model-comparisons",
    "href": "slides/foko4_20250505.html#model-comparisons",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Model Comparisons",
    "text": "Model Comparisons\n\nBased on approaches suggested by Law (2021), Lacoste, Laviolette, and Marchand (2012), and others.\n\n\n\n\n\n\n\n\n\nFigure¬†2: Paired samples of specifications tested against each other, paired by common denominators through other specifications."
  },
  {
    "objectID": "slides/foko4_20250505.html#model-comparisons-1",
    "href": "slides/foko4_20250505.html#model-comparisons-1",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Model Comparisons",
    "text": "Model Comparisons\n\nBased on approaches suggested by Law (2021), Lacoste, Laviolette, and Marchand (2012), and others.\n\n\n\n\n\n\n\n\nFigure¬†3: Graph depicting symbolic parameter comparison of two specifications."
  },
  {
    "objectID": "slides/foko4_20250505.html#specification-curve-analysis-1",
    "href": "slides/foko4_20250505.html#specification-curve-analysis-1",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Specification Curve Analysis",
    "text": "Specification Curve Analysis\n\n\nFigure¬†4: Specification curve analysis of 585 unique configurations across 4 mechanisms."
  },
  {
    "objectID": "slides/foko4_20250505.html#data-preselection-strategy",
    "href": "slides/foko4_20250505.html#data-preselection-strategy",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Data Preselection Strategy",
    "text": "Data Preselection Strategy\n\nDefinitionResultsTabular ResultsCode\n\n\n\n\n\n\n\n\nFigure¬†5: Schematic diagram of different data preselection strategies and how subsets are determined for each mechanism M and individual i.\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†6: Main effects of data preselection strategy relative to overall AUC-ROC. Lines indicate 90%-HDI.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison\nFull Data\nGT diff. Baseline\nGT diff. All\nSR diff. Baseline\nSR diff. All\n\n\n\n\nAgainst overall AUC-ROC\n-0.046 [-0.051; -0.040]\n0.030 [0.024; 0.035]\n0.027 [0.022; 0.032]\n0.007 [0.002; 0.013]\n-0.018 [-0.024; -0.013]\n\n\nFull Data\n‚Äì\n-0.075 [-0.081; -0.069]\n0.075 [0.070; 0.081]\n0.028 [0.022; 0.033]\n0.053 [0.047; 0.059]\n\n\nGT diff. Baseline\n‚Äì\n‚Äì\n0.003 [-0.004; 0.009]\n-0.048 [-0.054; -0.042]\n-0.022 [-0.028; -0.017]\n\n\nGT diff. All\n‚Äì\n‚Äì\n‚Äì\n-0.045 [-0.051; -0.039]\n-0.020 [-0.026; -0.013]\n\n\nSR diff. Baseline\n‚Äì\n‚Äì\n‚Äì\n‚Äì\n-0.026 [-0.032; -0.019]\n\n\n\n\n\n\nmodel_dataverse &lt;- stan_lmer(\n  aucroc ~ -1 + dataverse \n  + (1| type)\n  + (1| classifier)\n  + (1| specification)\n  + (1| preprocessing) \n  + (1| tested_class)\n  + (1| alternative_class), \n  data = data_aucroc, \n  prior = normal(0,10),\n  prior_intercept = normal(mean_aucroc,sd_aucroc),\n  chains = 4,\n  iter = 4000,\n  cores = 12\n)"
  },
  {
    "objectID": "slides/foko4_20250505.html#model-selection",
    "href": "slides/foko4_20250505.html#model-selection",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Model Selection",
    "text": "Model Selection\n\nDefinitionResultsTabular ResultsCode\n\n\n\n\n\n\n\n\nFigure¬†7: Schematic for model selection and specifications within the model(s). Random Forest, Mean Top-5 + Random Forest, and Top-5 Similarity are all based on SBERT embeddings. Deepseek R1 only classified texts based on data that was not preprocessed.\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†8: Results of group level classifier relative to overall AUC-ROC, and Results of specifications relative to overall performance of group level classifier. Lines indicate 90%-HDI.\n\n\n\n\n\n\n\n\nClassifier\nŒî AUC-ROC\n95% CI\n\n\n\n\nDeepseek R1\n0.06\n[0.04; 0.07]\n\n\nRandom Forest\n0.04\n[0.03; 0.05]\n\n\nMean Top-5 + RF\n0.00\n[-0.01; 0.01]\n\n\nTop-5 Similarity\n-0.06\n[-0.07; -0.05]\n\n\n\n\n\nmodel_hierarchical_aucroc &lt;- stan_lmer(\n  aucroc ~ -1 + classifier \n    + (1 | classifier:config_combined)\n    + (1 | type)\n    + (1 | dataverse)\n    + (1 | tested_class)\n    + (1 | alternative_class),\n  data = data_aucroc,\n  prior = normal(0,10), ## data has been centered around 0 before calculations\n  prior_intercept =  normal(mean_aucroc,sd_aucroc), ## data has been centered around 0 before calculations\n  chains = 4, \n  iter = 4000,\n  cores=12,\n  refresh = 100\n)\n\n\n\n\n[Footnote]: Deepseek R1 was only performed on no pre-processing due to time and budget reasons. One run of all classifications with Deepseek R1 took about 60-70 hours. Additionally, there is evidence that for Chat-Based Decoders, pre-processing is not as relevant as for embedding-generating algorithms (source, source, source), and may even benefit them by providing additional context."
  },
  {
    "objectID": "slides/foko4_20250505.html#comparison-type",
    "href": "slides/foko4_20250505.html#comparison-type",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Comparison Type",
    "text": "Comparison Type\n\nDefinitionResultsTabular ResultsCode\n\n\n\n\n\n\n\n\nFigure¬†9: Schematic for comparison types of comparing mechanisms against each other.\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†10: Results of group level comparison type relative to overall AUC-ROC. Lines indicate 90%-HDI.\n\n\n\n\n\n\n\n\n\nOne vs.¬†One\nOne vs.¬†All\nAll vs.¬†All\n\n\n\n\n0.009[0.005; 0.012]\n‚àí0.019[‚àí0.024; ‚àí0.013]\n‚àí0.009[‚àí0.014; ‚àí0.003]\n\n\n\n\n\n\nmodel_type &lt;- stan_glm(\n  aucroc ~ -1 + type \n  + (1| classifier)\n  + (1| specification)\n  + (1| dataverse)\n  + (1| tested_class)\n  + (1| alternative_class), \n  data = data_aucroc, \n  prior = normal(0,10),\n  prior_intercept = normal(mean_aucroc,sd_aucroc),\n  chains = 4,\n  iter = 4000,\n  cores = 12\n)"
  },
  {
    "objectID": "slides/foko4_20250505.html#mechanism",
    "href": "slides/foko4_20250505.html#mechanism",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Mechanism",
    "text": "Mechanism\n\nDefinitionResultsTabular ResultsCode\n\n\n\n\n\n\n\n\nFigure¬†11: Visual illustration of the four manipulations to which participants were subjected in a between-subjects design.\n\n\n\n\n\n\n\n\nClassification performance of mechanisms relative to overall AUC-ROC.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCondition\nAgainst All\nAgainst Other\nAgainst Baseline\nAgainst Knowledge\nAgainst Need\n\n\n\n\nBaseline\n-0.011 [-0.083, 0.061]\n-0.059 [-0.131, 0.014]\n‚Äì\n‚Äì\n‚Äì\n\n\nKnowledge\n0.035 [-0.037, 0.106]\n0.026 [-0.046, 0.098]\n0.040 [-0.032, 0.111]\n‚Äì\n‚Äì\n\n\nNeed\n-0.008 [-0.080, 0.062]\n-0.033 [-0.105, 0.038]\n-0.011 [-0.083, 0.059]\n0.019 [-0.052, 0.091]\n‚Äì\n\n\nSocial Norms\n0.009 [-0.062, 0.081]\n0.029 [-0.043, 0.100]\n0.028 [-0.043, 0.099]\n0.061 [-0.011, 0.132]\n0.017 [-0.055, 0.087]\n\n\n\n\n\n\nmodel_mechanisms &lt;- stan_glmer(\n  aucroc ~ -1 + tested_class \n    + (1 | classifier:config_combined) \n    + (1|preprocessing)\n    + (1|alternative_class)\n    + (1|type)\n    + (1|dataverse),\n  data = data_aucroc,\n  prior = normal(0,10),\n  prior_intercept =  normal(mean_aucroc,sd_aucroc),\n  chains = 4, \n  iter = 4000,\n  cores=12,\n  refresh = 1\n)"
  },
  {
    "objectID": "slides/foko4_20250505.html#reduced-specification-curve",
    "href": "slides/foko4_20250505.html#reduced-specification-curve",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Reduced Specification Curve",
    "text": "Reduced Specification Curve\n\n\nFigure¬†12: Reduced Plot with only influential classifiers displayed. Classifiers displayed are Deepseek R1 with prompt type ‚Äúboth‚Äù and all SBERT based algorithms embedding pooling MAX. All data used is based on transcriptions that were not further pre-processed. Only ‚ÄúOne vs.¬†One‚Äù and ‚ÄúOne vs.¬†All‚Äù comparisons are displayed."
  },
  {
    "objectID": "slides/foko4_20250505.html#explore-the-results-yourself",
    "href": "slides/foko4_20250505.html#explore-the-results-yourself",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Explore the Results yourself",
    "text": "Explore the Results yourself\n\n  https://saboustocker.shinyapps.io/webapp_analysis/"
  },
  {
    "objectID": "slides/foko4_20250505.html#implications-of-results",
    "href": "slides/foko4_20250505.html#implications-of-results",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Implications of Results",
    "text": "Implications of Results\n\nUtilizing verbal protocols as data can be used to diagnose state-specific mechanisms influencing decisions under risk and uncertainty!\nPrompt-based strategies and embedding-based strategies (if done right) work equally well.\nConsider what population the data comes from."
  },
  {
    "objectID": "slides/foko4_20250505.html#limitations",
    "href": "slides/foko4_20250505.html#limitations",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Limitations",
    "text": "Limitations\n\nSample size: ~75 per group\n\nNo additional fine-tuning in models - potential to work even better with fine-tuned weights\n\nControllability of context by experimental setup"
  },
  {
    "objectID": "slides/foko4_20250505.html#your-questions",
    "href": "slides/foko4_20250505.html#your-questions",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Your questions?",
    "text": "Your questions?"
  },
  {
    "objectID": "slides/foko4_20250505.html#my-questions",
    "href": "slides/foko4_20250505.html#my-questions",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "My questions",
    "text": "My questions\n\nHow can I assess the impact of credibly better specifications (effect size)?\nResearcher degrees of (reporting) freedom?\n\n\n\nAnd some administrative questions for Renato\n\nIs it okay for me to have public repositories in relation to my Master‚Äôs thesis on my personal GitHub (applet)?\nHow should we submit the final Master‚Äôs Thesis (PDF as E-Mail attachment, print, to whom, submission in official UZH tool by us or supervisor, ‚Ä¶)?"
  },
  {
    "objectID": "slides/foko4_20250505.html#section",
    "href": "slides/foko4_20250505.html#section",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "",
    "text": "‚Ä¶ and for the last time ‚Ä¶ \n\n(unless you decide to fail me and I have to rewrite another Master‚Äôs thesis)‚Ä¶\n\n\n\n\nThank you!"
  },
  {
    "objectID": "slides/foko4_20250505.html#bibliography",
    "href": "slides/foko4_20250505.html#bibliography",
    "title": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "section": "Bibliography",
    "text": "Bibliography\n\n\n\n\nLacoste, Alexandre, Francois Laviolette, and Mario Marchand. 2012. ‚ÄúBayesian Comparison of Machine Learning Algorithms on Single and Multiple Datasets.‚Äù 2012.\n\n\nLaw, Jonny. 2021. ‚ÄúBayesian Inference and Functional Programming - Model Comparison with Hierarchical Models.‚Äù September 27, 2021. https://jonnylaw.rocks/posts/2021-09-27-model-comparison/.\n\n\nSimonsohn, Uri, Joseph P. Simmons, and Leif D. Nelson. 2020. ‚ÄúSpecification Curve Analysis.‚Äù Nature Human Behaviour 4 (11): 1208‚Äì14. https://doi.org/10.1038/s41562-020-0912-z."
  },
  {
    "objectID": "slides/HSG_CBT.html#about-me",
    "href": "slides/HSG_CBT.html#about-me",
    "title": "Job Talk @ IBT-HSG",
    "section": "About Me",
    "text": "About Me"
  },
  {
    "objectID": "slides/HSG_CBT.html#section",
    "href": "slides/HSG_CBT.html#section",
    "title": "Job Talk @ IBT-HSG",
    "section": "",
    "text": "Nature\n\n\n\n\nNurture\n\n\n\n\nNugget"
  },
  {
    "objectID": "slides/HSG_CBT.html#a-specification-curve-evaluation-of-nlp-classifiers-for-state-specific-psychological-mechanisms-influencing-decisions-under-risk-and-uncertainty",
    "href": "slides/HSG_CBT.html#a-specification-curve-evaluation-of-nlp-classifiers-for-state-specific-psychological-mechanisms-influencing-decisions-under-risk-and-uncertainty",
    "title": "Job Talk @ IBT-HSG",
    "section": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty",
    "text": "A Specification Curve Evaluation of NLP Classifiers for state-specific psychological Mechanisms influencing Decisions under Risk and Uncertainty\nMaster‚Äôs Thesis Sabou Rani Stocker  Cognitive and Behavioral Decision Research  University of Zurich"
  },
  {
    "objectID": "slides/HSG_CBT.html#background",
    "href": "slides/HSG_CBT.html#background",
    "title": "Job Talk @ IBT-HSG",
    "section": "Background",
    "text": "Background\n\nmany proposed state-dependent influences,  little research on their occurence in real life\n\nLob, Fischer, and Frey (2025), Holleman et al. (2020), Quinan et al. (2015)\n\nnatural language as data and NLP as method\n\nBinz et al. (2025), Ostrovsky and Newell (2024),\n\npromising first results but no systematic evaluation\n\nHeitz, Schneider, and Langer (2024), Fischer, Lob, and Frey (2024), Bhatia (2024), and others"
  },
  {
    "objectID": "slides/HSG_CBT.html#aim-research-question",
    "href": "slides/HSG_CBT.html#aim-research-question",
    "title": "Job Talk @ IBT-HSG",
    "section": "Aim & Research Question",
    "text": "Aim & Research Question\nAim\nSystematic comparison of algorithms harnessing NLP on their capabilities and limitations in diagnosing state-specific mechanisms influencing people when making decisions  \nResearch Question\nHow reliably can we identify state-specific mechanisms from natural language influencing people in decision-making?"
  },
  {
    "objectID": "slides/HSG_CBT.html#methods",
    "href": "slides/HSG_CBT.html#methods",
    "title": "Job Talk @ IBT-HSG",
    "section": "Methods",
    "text": "Methods\nData Collection\n\n\n\nrandomized-controlled study: four groups (baseline, 3 manipulations)\nonline experiment, \\(n\\) = 320\nsimultaneous performance of think-aloud protocols\n\nPayne (1994), Smagorinsky (1998), and others\n\n\n\n      \n\n\nManipulation implementations based on: Frey and Fischer (2024), Pieters and Wedel (2004), Mitchell and Olson (1981), Shi, Li, and Chumnumpan (2020), Gerrard et al. (2008), and others\n\n\n\n\n\nBaseline Condition\n\n\n\n\n\nSocial Norms Gerrard et al. (2008)\n\n\n\n\n\nKnowledge on situation Fischhoff et al. (1978)\n\n\n\n\n\nNeed Mishra (2014), Mishra, Barclay, and Sparks (2017)"
  },
  {
    "objectID": "slides/HSG_CBT.html#methods-1",
    "href": "slides/HSG_CBT.html#methods-1",
    "title": "Job Talk @ IBT-HSG",
    "section": "Methods",
    "text": "Methods\nAnalysis"
  },
  {
    "objectID": "slides/HSG_CBT.html#methods-2",
    "href": "slides/HSG_CBT.html#methods-2",
    "title": "Job Talk @ IBT-HSG",
    "section": "Methods",
    "text": "Methods\nSpecification Curve Analysis\n\nSimonsohn, Simmons, and Nelson (2020)\n\n\n315 main specifications\n3‚Äô900 specifications including robustness checks"
  },
  {
    "objectID": "slides/HSG_CBT.html#results",
    "href": "slides/HSG_CBT.html#results",
    "title": "Job Talk @ IBT-HSG",
    "section": "Results",
    "text": "Results\n\n\n\n\n\n\n\n\nSupplementary Results"
  },
  {
    "objectID": "slides/HSG_CBT.html#results-1",
    "href": "slides/HSG_CBT.html#results-1",
    "title": "Job Talk @ IBT-HSG",
    "section": "Results",
    "text": "Results\nStatistical Significance\n\n\n\n\nFurther Results"
  },
  {
    "objectID": "slides/HSG_CBT.html#implications",
    "href": "slides/HSG_CBT.html#implications",
    "title": "Job Talk @ IBT-HSG",
    "section": "Implications",
    "text": "Implications\nMethodological\n\ngiven the right circumstances, psychological mechanisms can be inferred from natural language\nmethodological approach \\(\\geq\\) mechanism\n\nPractical\n\nscaleable analysis of text-data\nviable to test (co-)occurrence of mechanisms in naturalistic scenarios\nvalidation with real world data & co-occurring mechanisms pending"
  },
  {
    "objectID": "slides/HSG_CBT.html#the-privacy-convenience-paradox",
    "href": "slides/HSG_CBT.html#the-privacy-convenience-paradox",
    "title": "Job Talk @ IBT-HSG",
    "section": "The Privacy-Convenience-Paradox",
    "text": "The Privacy-Convenience-Paradox\n\nprivacy calculus: theory on mental cost-benefit-analysis for sharing private information\n\n\nDinev and Hart (2006), Beke et al. (2022)\n\n\nprivacy-convenience-paradox: preference and actual behavior are different from each other\n\n\nAckerman, Cranor, and Reagle (1999), Zhang, Koivum√§ki, and Chalmers (2024)\n\n\n\n\n\nModel adapted from: Beke et al. (2022), Dinev and Hart (2006)"
  },
  {
    "objectID": "slides/HSG_CBT.html#the-privacy-convenience-paradox-1",
    "href": "slides/HSG_CBT.html#the-privacy-convenience-paradox-1",
    "title": "Job Talk @ IBT-HSG",
    "section": "The Privacy-Convenience-Paradox",
    "text": "The Privacy-Convenience-Paradox\n\nDecision-research: Humans do not act rational\n\n\nArkes, Gigerenzer, and Hertwig (2016)\n\n\\(\\rightarrow\\) Bounded Rationality\n\nSimon (1955)\n\n\\(\\rightarrow\\) Dual-Process Theory\n\nStanovich and West (2000), Kahneman (2011)\n\n\n\n\n\nModel adapted from: Beke et al. (2022), Dinev and Hart (2006)\n\n\nExtension of Model"
  },
  {
    "objectID": "slides/HSG_CBT.html#research-question-1",
    "href": "slides/HSG_CBT.html#research-question-1",
    "title": "Job Talk @ IBT-HSG",
    "section": "Research Question",
    "text": "Research Question\n\n(How) can we explain discrepancies between preference and behavior in online disclosure of private data through theories of bounded rationality and heuristics targeting the fast systems of dual-process systems?"
  },
  {
    "objectID": "slides/HSG_CBT.html#a-formal-model-of-the-privacy-convenience-paradox",
    "href": "slides/HSG_CBT.html#a-formal-model-of-the-privacy-convenience-paradox",
    "title": "Job Talk @ IBT-HSG",
    "section": "A Formal Model of the Privacy-Convenience Paradox",
    "text": "A Formal Model of the Privacy-Convenience Paradox\n\\[\n\\text{ABH} \\overset{?}{=}\n\\frac{1}{1+e^{-k(\\text{WTS}+\\color{3062FF}{\\alpha \\cdot \\text{IC}}+\\color{A4D233}{\\beta \\cdot \\text{EW}} + \\color{A27200}{\\gamma\\cdot \\text{IC}\\cdot \\text{EW}})}}\n\\]\n\n\n\n\nExtended Formal Model - Dynamic Visualization"
  },
  {
    "objectID": "slides/HSG_CBT.html#approach",
    "href": "slides/HSG_CBT.html#approach",
    "title": "Job Talk @ IBT-HSG",
    "section": "Approach",
    "text": "Approach\n\nexperimental data collection\nformal modelling of privacy calculus + ‚Äúbehavioral privacy calculus‚Äù\n\nvalidation against theory\nvalidation against correlational data (RWD)\nvalidation against scientific regret minimization approach\n\n\n\nAgrawal, Peterson, and Griffiths (2020)\n\n\nExperimental Setup - Scientific Regret Minimization"
  },
  {
    "objectID": "slides/HSG_CBT.html#added-value",
    "href": "slides/HSG_CBT.html#added-value",
    "title": "Job Talk @ IBT-HSG",
    "section": "Added Value",
    "text": "Added Value\nTheory\n\nempirical validation of model\n\nbetter model to predict consumer behavior\n\n\nPractice\n\nmaximisation of benefits\n\npolicy: use resources where it is most effective\nconsumers: enabling to make decisions congruent with preference"
  },
  {
    "objectID": "slides/HSG_CBT.html#supplementary-data",
    "href": "slides/HSG_CBT.html#supplementary-data",
    "title": "Job Talk @ IBT-HSG",
    "section": "Supplementary Results",
    "text": "Supplementary Results\n\nhttps://saboustocker.shinyapps.io/webapp_analysis/"
  },
  {
    "objectID": "slides/HSG_CBT.html#further-results",
    "href": "slides/HSG_CBT.html#further-results",
    "title": "Job Talk @ IBT-HSG",
    "section": "Further Results: Statistical Significance",
    "text": "Further Results: Statistical Significance"
  },
  {
    "objectID": "slides/HSG_CBT.html#experimental-setup",
    "href": "slides/HSG_CBT.html#experimental-setup",
    "title": "Job Talk @ IBT-HSG",
    "section": "Experimental Setup",
    "text": "Experimental Setup\n\n\n\n\nMaterial inspired by Nouwens et al. (2020), Litman-Navarro (2019), Acquisti et al. (2018), Zhang, Koivum√§ki, and Chalmers (2024)\n\n\n\n\nImages Source: bbc.uk.com, ch.indeed.com"
  },
  {
    "objectID": "slides/HSG_CBT.html#srm",
    "href": "slides/HSG_CBT.html#srm",
    "title": "Job Talk @ IBT-HSG",
    "section": "Scientific Regret Minimization",
    "text": "Scientific Regret Minimization\n\nAgrawal, Peterson, and Griffiths (2020)"
  },
  {
    "objectID": "slides/HSG_CBT.html#extended-model",
    "href": "slides/HSG_CBT.html#extended-model",
    "title": "Job Talk @ IBT-HSG",
    "section": "Extended theoretical Model",
    "text": "Extended theoretical Model\n\n\n\n\nModel adapted from: Beke et al. (2022), Dinev and Hart (2006)"
  },
  {
    "objectID": "slides/HSG_CBT.html#dynamic-model",
    "href": "slides/HSG_CBT.html#dynamic-model",
    "title": "Job Talk @ IBT-HSG",
    "section": "Dynamic Visualization of Model",
    "text": "Dynamic Visualization of Model"
  },
  {
    "objectID": "slides/HSG_CBT.html#formal-model",
    "href": "slides/HSG_CBT.html#formal-model",
    "title": "Job Talk @ IBT-HSG",
    "section": "Alternative Formulas of the PC-Paradox",
    "text": "Alternative Formulas of the PC-Paradox\n\\[\n{\\text{ABH} \\overset{?}{=}}\n\\left\\{\n\\begin{aligned}\n&\\frac{1}{1+e^{-k(\\text{WTS})}} \\\\[0.6em]\n&\\frac{1}{1+e^{-k(\\text{WTS}+\\color{red}{\\alpha \\cdot \\text{IC}}+\\color{blue}{\\beta \\cdot \\text{EW}})}} \\\\[0.6em]\n&\\frac{1}{1+e^{-k(\\text{WTS}+\\color{red}{\\alpha \\cdot \\text{IC}}+\\color{blue}{\\beta \\cdot \\text{EW}} + \\color{green}{\\gamma\\cdot \\text{IC}\\cdot \\text{EW}})}}\n\\end{aligned}\n\\right.\n\\]"
  }
]